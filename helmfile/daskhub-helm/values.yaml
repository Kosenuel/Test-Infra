# ---------------------------------------------------
# 1. Dask Gateway Settings (Keep at top level)
# ---------------------------------------------------
dask-gateway:
  enabled: true
  gateway:
    auth:
      type: jupyterhub
      jupyterhub:
        apiToken: put_your_dask_gateway_api_token_here
    extraConfig: # cluster_max_memory was given its value in bytes calculated as 16 GiB.
      dasklimits: |
        c.ClusterConfig.cluster_max_cores = 4
        c.ClusterConfig.cluster_max_memory = 16 * 1024**3
        c.ClusterConfig.cluster_max_workers = 3
        c.ClusterConfig.idle_timeout = 1200 
      optionHandler: |
        from dask_gateway_server.options import Options, Integer, Float, String
        def options_handler(options):
          if ":" not in options.image:
            raise ValueError("When specifying an image you must also provide a tag")
          return {
            "worker_cores": options.worker_cores,
            "worker_memory": int(options.worker_memory * 2 ** 30),
          }
        c.Backend.cluster_options = Options(
          Integer("worker_cores", default=1, min=1, max=2, label="Worker Cores"),
          Float("worker_memory", default=4, min=2, max=6, label="Worker Memory (GiB)"),
          String("image", default="quay.io/globalcoast/protocoast-notebook:main", label="Image"),
          handler=options_handler,
        )

dask-kubernetes:
  enabled: false
  # worker:
  #   image:
  #     name: "quay.io/globalcoast/protocoast-notebook"
  #     tag: "main"

# ---------------------------------------------------
# 2. JupyterHub Settings
# ---------------------------------------------------
jupyterhub:
  hub:
    db:
      type: sqlite-pvc
      pvc:
        storageClassName: "csi-cinder-sc-delete"
        accessModes:
          - ReadWriteOnce
        storage: 1Gi
    config:
      JupyterHub:
        authenticator_class: generic-oauth
      GenericOAuthenticator:
        client_id: "put_the_client_id_of_the_oauth_app_here"
        client_secret: "put_the_client_secret_of_the_oauth_app_here"
        oauth_callback_url: "https://protocoast.vm.fedcloud.eu/hub/oauth_callback"
        authorize_url: "https://aai-demo.egi.eu/auth/realms/egi/protocol/openid-connect/auth"
        token_url: "https://aai-demo.egi.eu/auth/realms/egi/protocol/openid-connect/token"
        userdata_url: "https://aai-demo.egi.eu/auth/realms/egi/protocol/openid-connect/userinfo"
        scope:
          - openid
          - profile
          - email
          - entitlements
        username_key: "preferred_username"
        allow_all: true
    extraConfig: 
      protocoast-profiles: |
        # ---------------------------------------------------
        # 1. GLOBAL RESOURCE LIMITS (Ephemeral Storage)
        # ---------------------------------------------------
        # We are setting these here to bypass the Helm schema restrictions of configuring these values directly in the chart
        c.KubeSpawner.extra_resource_guarantees = {
          "ephemeral-storage": "4Gi"
          }
        c.KubeSpawner.extra_resource_limits = {
          "ephemeral-storage": "8Gi"
          }

        # ---------------------------------------------------
        # 2. PROFILE LIST (Notebook Types)
        # ---------------------------------------------------
        c.KubeSpawner.profile_list = [
          {
            'display_name': 'ProtoCoast - main',
            'slug': 'protocoast-main',
            'description': 'Start with quay.io/globalcoast/protocoast-notebook:main',
            'default': True,
            'kubespawner_override': {
              'image': 'quay.io/globalcoast/protocoast-notebook:main'
            }
          },
          {
            'display_name': 'ProtoCoast - develop',
            'slug': 'protocoast-develop',
            'description': 'Start with quay.io/globalcoast/protocoast-notebook:develop',
            'kubespawner_override': {
              'image': 'quay.io/globalcoast/protocoast-notebook:develop'
            }
          }
        ]
    services:
      dask-gateway:
        apiToken: put_your_dask_gateway_api_token_here

  # Networking  (under jupyterhub)
  proxy:
    service:
      type: ClusterIP
    https:
      enabled: false

  ingress:
    enabled: true
    annotations:
      cert-manager.io/cluster-issuer: letsencrypt-prod
      nginx.ingress.kubernetes.io/ssl-redirect: "true"
      nginx.ingress.kubernetes.io/proxy-body-size: "100m"
      ingress.class: nginx
    hosts:
      - protocoast.vm.fedcloud.eu
    tls:  
      - hosts:
          - protocoast.vm.fedcloud.eu
        secretName: protocoast-tls

  # Storage (under jupyterhub)
  singleuser:
    image: 
      name: "quay.io/globalcoast/protocoast-notebook"
      tag: "main"
    memory:
      limit: "10G"
      guarantee: "5G" 
    cpu:
      limit: 2
      guarantee: 1 
    storage:
      type: dynamic
      dynamic:
        storageClass: csi-cinder-sc-delete
      capacity: 50Gi

    networkPolicy: 
      enabled: false #Disable network policies for user pods to allow Dask Gateway communication
 
  prePuller:
    hook:
      enabled: false
    continuous:
      enabled: true

  scheduling:
    userScheduler:
      enabled: false
    podPriority:
      enabled: true
    userPlaceholder:
      enabled: false